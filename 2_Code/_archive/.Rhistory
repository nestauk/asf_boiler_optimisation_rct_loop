# Load packages
library(tidyverse) #----- Manipulating data (`case_when`)
library(janitor) #------- Useful for cleaning
library(stringr) #------- String operations (`str_wrap`)
library(purrr) #--------- Vectorization
library(data.table) #---- For transposing
library(readr) #--------- Reading csv files
library(summarytools) #-- Descriptive statistics
library(jtools) #-------- Regression outputs
library(lmtest) #-------- Linear regression tests
library(sandwich) #------ Robust SEs
# Data pathways
bas_dir <- "C:/Users/oli.berry/Documents/GitHub/asf_loop_flex_rct/"
data_path <- file.path(bas_dir, "1_Data")
out_dir <- file.path(bas_dir, "3_Outputs")
# Set seed
set.seed(20230103)
start_time <- Sys.time()
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
### ~~~ Summary of code ~~~ ###
## This code conducts simulated power calculations for the Loop Flexibility RCT.
## The outcome is electricity consumption during a Demand Flexibility Service event.
## The data comprise electricity consumption the most recent event (Wh) for
## customers of Loop who have opted into the scheme overall.
## The code randomly allocates each customer to either a Treatment group or a
## Control group. It then uses the standard error of the Treatment estimate to
## determine the minimum detectable effect.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
### ~~~ Part 0: Importing data ~~~ ###
# Import dummy data
data <- read_csv(paste(data_path, "EventData.csv", sep="/")) |>
janitor::clean_names()
#~~~ Cleaning and exploring
head(data)
str(data)
# Creating opt-out variable
data <- data |>
mutate(opt_in = case_when(
took_part == "TRUE" ~ 1,
took_part == "FALSE" ~ 0,
TRUE ~ 99
))
## Note, opting in to an event is our secondary outcome measure. We don't use
## this variable for the power calculations, but it is helpful to see.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
### ~~~ Part 1: Exploring data ~~~ ###
# ~~ I. Usage ~~ #
# Summary statistics
summary(data$usage)
descr(data$usage)
nrow(data) ## 14,616 rows
length(data$usage[data$usage == 0]) ## 348 zeros (roughly 2%)
# Graphing
hist(data$usage, breaks = 1e3) ## Looks very skewed, with a lot of zeros
hist(log(data$usage[data$usage != 0]), breaks = 1e3) ## Looks more normal
# ~~ II. Opt ins ~~ #
summary(data$opt_in)
tabyl(data$opt_in) # 61% opt-in
sample_seq <- seq(1e3, 14e3, 500)
# Sim count
sim <- sim + 1
sims <- length(sample_seq) * 30 ## Number of simulations
##sims <- length(sample_seq) * 3 ## Number of simulations
sim <- 0
# Sim count
sim <- sim + 1
#~~~ Selecting sample size
## We create a new dataframe so we don't need to import the data each time.
# Creating random number and ordering
data_to_use <- data |>
filter(!duplicated(id)) |> ## Removing duplicates (there aren't any fortunately)
mutate(rand = runif(1)) |> ## Generating random number
arrange(rand) ## Sorting by random number
# Selecting sample for this simulation
sample <- sample_seq[(sim %% (length(sample_seq)) +1)] ## This is a way to subsequently sample from sample_seq
# Subsetting to correct sample size
data_to_use <- data_to_use |>
filter(row_number() <= sample)
#~~~ Random treatment assignment
## We are using simple randomisation
data_to_use <- data_to_use |>
mutate(treat_num = sample(2, 1, replace = TRUE)) |>
mutate(treatment = case_when(
treat_num == 1 ~ "Control",
treat_num == 2 ~ "Treatment",
TRUE ~ "Missing"
))
glm(usage ~ treatment, family = "poisson", data = data_to_use)
View(data_to_use)
data_to_use <- data_to_use |>
group_by(id) |>
mutate(treat_num = sample(2, 1, replace = TRUE)) |>
ungroup() |>
mutate(treatment = case_when(
treat_num == 1 ~ "Control",
treat_num == 2 ~ "Treatment",
TRUE ~ "Missing"
))
glm(usage ~ treatment, family = "poisson", data = data_to_use)
glm(usage ~ treatment, family = poisson, data = data_to_use)
glm(usage ~ treatment, data = data_to_use)
